{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "from performance_test import *\n",
    "from kafka_producer import *\n",
    "#from directNeo4jImporter import *\n",
    "from node_deletion import *\n",
    "from correctness_test import *\n",
    "from partition_changer import *\n",
    "from heapSize_changer import *\n",
    "from streams_conf_changer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter\n",
    "\n",
    "#### General Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## put in settings(?)\n",
    "\n",
    "#name of database\n",
    "\n",
    "node_labels = {\n",
    "    'original': {\n",
    "        'block'       : 'Block',\n",
    "        'transaction' : 'Transaction',\n",
    "        'address'     : 'Address'\n",
    "    },\n",
    "    'test': {\n",
    "        'block'       : 'Block_test',\n",
    "        'transaction' : 'Transaction_test',\n",
    "        'address'     : 'Address_test'\n",
    "    }\n",
    "}\n",
    "\n",
    "neo4j_port = str(7687)\n",
    "\n",
    "# parameters which need to bee handed over and retrieved from a settings file?\n",
    "conf_file_path = '../example_streams.conf'\n",
    "#conf_file_path = '../streams.conf'\n",
    "\n",
    "path_to_neo4j_conf_directory = '/etc/neo4j/'\n",
    "path_to_streams_conf = path_to_neo4j_conf_directory + 'streams.conf'\n",
    "\n",
    "kafka_topics =   {\n",
    "    'transaction': 'transactions', \n",
    "    'block': 'blocks'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing parameters\n",
    "\n",
    "# set to false if test_nodes are inserted \n",
    "evaluate_original = True\n",
    "\n",
    "\n",
    "# block heights\n",
    "if evaluate_original == True:\n",
    "    start_block_height = 591106  \n",
    "    end_block_height   = start_block_height + 1\n",
    "else:\n",
    "    start_block_height = 1 \n",
    "    end_block_height   = start_block_height + 5\n",
    "\n",
    "\n",
    "    \n",
    "##############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# check correctness of nodes inserted\n",
    "check_correctness = False\n",
    "\n",
    "# matching input on previous transactions   # (address not transaction)\n",
    "match_on_previous_add = True  #(?)\n",
    "\n",
    "# bypass kafka pipeline\n",
    "bypass_kafka = False \n",
    "\n",
    "# number of kafka partitions \n",
    "kafka_partitions_list = [1,2,4,8]\n",
    "\n",
    "# batching (?)\n",
    "batching_list = [1, 100, 400, 800]\n",
    "\n",
    "# neo4j heap size\n",
    "heap_size_list = [5, 8, 16, 32]\n",
    "# missing func for heap_size changer\n",
    "\n",
    "\n",
    "# to change throughout loop (!)\n",
    "kafka_partitions = 1\n",
    "batching_size = 1\n",
    "heap_size = 5\n",
    "\n",
    "\n",
    "######\n",
    "\n",
    "\n",
    "# deleting Nodes at the end of each run\n",
    "deleteNodes = True\n",
    "\n",
    "# Parameters configurations [kafka_partition,batching_value, match_on_previous_add, heap_size, bypass_kafka]\n",
    "\n",
    "configurations= []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table of all settings \n",
    "# for each set of settings (for each experiment run) make counter\n",
    "# -> experimentRun\n",
    "# (hand over to mismachtches)\n",
    "experimentRun = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Process\n",
    "\n",
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up results dataframe \n",
    "columns=[\n",
    "    'experimentRun',\n",
    "    'evaluate_original',\n",
    "    'start_block_height',\n",
    "    'end_block_height',\n",
    "    'kafka_partitions',\n",
    "    'batching',\n",
    "    'match_on_previous_add',\n",
    "    'heap_size',\n",
    "    'bypass_kafka',\n",
    "    'check_correctness',\n",
    "    'endTimePart1', \n",
    "    'endTimePart2', \n",
    "    'totalExecutionTime', \n",
    "    'timeOutReached']\n",
    "\n",
    "results_df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory structure\n",
    "result_dir     = 'results'\n",
    "mismatches_dir = 'mismatches'\n",
    "if os.path.exists(result_dir) == False:\n",
    "    os.makedirs(result_dir)\n",
    "if os.path.exists(os.path.join(result_dir, mismatches_dir)) == False:\n",
    "    os.makedirs(os.path.join(result_dir, mismatches_dir))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect original nodes that need to be deleted\n",
    "if evaluate_original == True:\n",
    "    \n",
    "    # ToDo: check correctness of starting hight\n",
    "    # #query neo4j if \n",
    "\n",
    "\n",
    "    # collecting nodes for \n",
    "    deletion_nodes = getDeletionList(start_block_height = start_block_height, \n",
    "                                     end_block_height = end_block_height, \n",
    "                                     label_address = node_labels['original']['address'], \n",
    "                                     neo4j_location = 'server', \n",
    "                                     neo4j_port = '7687')\n",
    "    \n",
    "    ### (!) start loop afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deletion_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change cypher templates\n",
    "\n",
    "changeStreamsFile(path = path_to_streams_conf, \n",
    "                  kafka_topics = kafka_topics, \n",
    "                  evaluate_original = evaluate_original, \n",
    "                  matchOnAddress = match_on_previous_add, \n",
    "                  getTemplate = True,  # to retrieve cypher template or query for direct insertion \n",
    "                  node_labels = node_labels, \n",
    "                  evaluation = True)\n",
    "\n",
    "# insert a sleeping timer in here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if partitions change or heap size changes, then stop neo4j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set kafka partitions\n",
    "#partitionChanger(partitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change_heap_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if partitions change or heap size changes, then start neo4j\n",
    "\n",
    "# sleeping timer or is there a way to see whether neo4j ready?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertion & Performance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "endTimePart1, endTimePart2, totalExecutionTime, timeOutReached = runPerformanceTest(evaluate_original, \n",
    "                                                                                    node_labels, \n",
    "                                                                                    bypass_kafka, \n",
    "                                                                                    start_block_height, \n",
    "                                                                                    end_block_height, \n",
    "                                                                                    match_on_previous_add, \n",
    "                                                                                    kafka_topics)\n",
    "\n",
    "#print(endTimePart1, endTimePart2, totalExecutionTime, timeOutReached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(endTimePart1, endTimePart2, totalExecutionTime, timeOutReached)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctness Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if evaluate_original == False and check_correctness == True:\n",
    "    checkCorrectness(start_block_height, \n",
    "                     end_block_height,\n",
    "                     node_labels,\n",
    "                     neo4j_port,\n",
    "                     experimentRun, \n",
    "                     printMismatches=False, \n",
    "                     saveMismatches=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[\n",
    "    experimentRun,\n",
    "    evaluate_original,\n",
    "    start_block_height,\n",
    "    end_block_height,\n",
    "    kafka_partitions,\n",
    "    batching_size,\n",
    "    match_on_previous_add,\n",
    "    heap_size,\n",
    "    bypass_kafka,\n",
    "    check_correctness,\n",
    "    endTimePart1, \n",
    "    endTimePart2, \n",
    "    totalExecutionTime, \n",
    "    timeOutReached]]\n",
    "\n",
    "new_results_entry = pd.DataFrame(columns=columns, data = data)\n",
    "results_df=pd.concat([results_df,new_results_entry]).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deletion of inserted nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out to enable deletion\n",
    "if deleteNodes == True:\n",
    "    if evaluate_original == True:\n",
    "        deleteOriginalEvaluationNodes(deletion_nodes = deletion_nodes, \n",
    "                                      node_labels = node_labels,\n",
    "                                      neo4j_location = 'server', \n",
    "                                      neo4j_port = '7687')\n",
    "    else:\n",
    "        deleteTestEvaluationNodes(node_labels = node_labels,\n",
    "                                  neo4j_location = 'server', \n",
    "                                  neo4j_port = '7687')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After loop - Evaluation Process cleanup\n",
    "\n",
    "Restore streams file\n",
    "- remove insertion time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('./results/evaluation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore streams file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changeStreamsFile(path = path_to_streams_conf, \n",
    "                  kafka_topics = kafka_topics, \n",
    "                  evaluate_original = True, \n",
    "                  matchOnAddress = True, \n",
    "                  getTemplate = True,  \n",
    "                  node_labels = node_labels, \n",
    "                  evaluation = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
